{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffK_AD2vQ6JS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 1.1: Data Loading and Initial Exploration\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#1.2 Read the CSV file from the URL\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/PDAI LIthan/car__1_.csv')\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n",
        "\n",
        "#1.3 Display the first 5 rows of the dataset to get an initial overview\n",
        "\n",
        "df.head(5)\n",
        "\n",
        "# =-1 all except last column\n",
        "x = df.iloc[ :,:-1 ]\n",
        "y = df.iloc[ :,-1 ]\n",
        "\n",
        "#Task 2: Data Splitting\n",
        "#2.1 Split the dataset into training and testing sets using the train_test_split function from sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.30, random_state= 42)\n",
        "\n",
        "\n",
        "#2.2 Display basic function about the training set using the info method\n",
        "x_train.info()\n",
        "\n",
        "#Task 3: Exploratory Data Analysis (EDA)\n",
        "\n",
        "#3.1 Remove the index column as it seems redundant.\n",
        "\n",
        "x_train.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "x_test.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "\n",
        "#3.2 Explore the distribution of car manufacturers in the dataset. Extract the manufacturer from the 'Name' column and create a new column named 'Manufacturer'.\n",
        "str_split_train = x_train[\"Name\"].str.split(\" \", expand = True)\n",
        "str_split_test = x_test[\"Name\"].str.split(\" \", expand = True)\n",
        "\n",
        "x_train['Manufacturer'] = str_split_train[0]\n",
        "x_test['Manufacturer'] = str_split_test[0]\n",
        "\n",
        "#3.3 Visualize the count of cars based on manufacturers using a countplot.\n",
        "\n",
        "sns.countplot (x = 'Manufacturer', data = x_train)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.xlabel(\"Manufacturer of Car\")\n",
        "plt.ylabel(\"Count of cars for each Manufacturer\")\n",
        "plt.title(\"Count of cars based on each Manufacturer\")\n",
        "\n",
        "#3.4 Drop the 'Name' column as it is no longer needed.\n",
        "\n",
        "x_train.drop([\"Name\"], axis = 1, inplace = True)\n",
        "x_test.drop([\"Name\"], axis = 1, inplace = True)\n",
        "\n",
        "#3.5 Remove the 'Location' column as it is not expected to significantly influence car prices.\n",
        "\n",
        "x_train.drop([\"Location\"], axis = 1, inplace = True)\n",
        "x_test.drop([\"Location\"], axis = 1, inplace = True)\n",
        "\n",
        "#4.2 Scale the 'Kilometers_Driven' column using MinMaxScaler.\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "df['Kilometers_Driven'] = scaler.fit_transform(df[['Kilometers_Driven']])\n",
        "\n",
        "#4.3 Extract the numerical values from the 'Mileage' column and handle missing values.\n",
        "\n",
        "mileage_train = x_train['Mileage'].str.split(\" \", expand = True)\n",
        "mileage_test = x_test['Mileage'].str.split(\" \", expand = True)\n",
        "\n",
        "x_train['Mileage'] = pd.to_numeric(mileage_train[0], errors ='coerce')\n",
        "x_test['Mileage'] = pd.to_numeric(mileage_test[0], errors ='coerce')\n",
        "\n",
        "print(sum(x_train['Mileage'].isnull()))\n",
        "print(sum(x_test['Mileage'].isnull()))\n",
        "\n",
        "#fill the missing value by using mean()\n",
        "x_train['Mileage'].fillna(x_train['Mileage'].astype(\"float64\").mean(), inplace = True)\n",
        "x_test['Mileage'].fillna(x_test['Mileage'].astype(\"float64\").mean(), inplace = True)\n",
        "\n",
        "#4.4 Process the 'Engine', 'Power', and 'Seats' columns by removing units, converting to numeric, and handling missing values.\n",
        "\n",
        "engine_train = x_train['Engine'].str.split(\" \", expand = True)\n",
        "engine_test = x_test['Engine'].str.split(\" \", expand = True)\n",
        "\n",
        "power_train = x_train['Power'].str.split(\" \", expand = True)\n",
        "power_test = x_test['Power'].str.split(\" \", expand = True)\n",
        "\n",
        "x_train['Engine'] = pd.to_numeric(engine_train[0], errors ='coerce')\n",
        "x_test['Engine'] = pd.to_numeric(engine_test[0], errors ='coerce')\n",
        "\n",
        "x_train['Power'] = pd.to_numeric(power_train[0], errors ='coerce')\n",
        "x_test['Power'] = pd.to_numeric(power_test[0], errors ='coerce')\n",
        "\n",
        "x_train['Engine'].fillna(x_train['Engine'].astype(\"float64\").mean(), inplace = True)\n",
        "x_test['Engine'].fillna(x_test['Engine'].astype(\"float64\").mean(), inplace = True)\n",
        "\n",
        "x_train['Power'].fillna(x_train['Power'].astype(\"float64\").mean(), inplace = True)\n",
        "x_test['Power'].fillna(x_test['Power'].astype(\"float64\").mean(), inplace = True)\n",
        "\n",
        "x_train['Seats'].fillna(x_train['Seats'].astype(\"float64\").mean(), inplace = True)\n",
        "x_test['Seats'].fillna(x_test['Seats'].astype(\"float64\").mean(), inplace = True)\n",
        "\n",
        "#4.5 Drop the 'New_Price' column due to a high number of missing values.\n",
        "\n",
        "x_train.drop([\"New_Price\"], axis = 1, inplace = True)\n",
        "x_test.drop([\"New_Price\"], axis = 1, inplace = True)\n",
        "\n",
        "#Task 4: Feature Engineering\n",
        "# Convert categorical columns ('Fuel_Type', 'Transmission', 'Owner_Type') into dummy variables.\n",
        "\n",
        "x_train = pd.get_dummies(x_train , columns = [\"Fuel_Type\", \"Transmission\", \"Owner_Type\", \"Manufacturer\"], drop_first = True)\n",
        "\n",
        "x_test = pd.get_dummies(x_test , columns = [\"Fuel_Type\", \"Transmission\", \"Owner_Type\", \"Manufacturer\"], drop_first = True)\n",
        "\n",
        "missing_cols = set(x_train.columns) - set(x_test.columns)\n",
        "for col in missing_cols:\n",
        "  x_test[col] = 0\n",
        "x_test = x_test[x_train.columns]\n",
        "\n",
        "#Task 5: Data Processing\n",
        "#5.1 Normalize Numerical Features.\n",
        "\n",
        "#5.2 Scale the datasets using StandardScaler.\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#Task 6: Model Training and Evaluation\n",
        "#6.1 Train a Linear Regression model on the preprocessed training data.\n",
        "\n",
        "lir = LinearRegression()\n",
        "lir.fit(x_train, y_train)\n",
        "y_pred = lir.predict(x_test)\n",
        "\n",
        "#6.2 Evaluate the performance of the Linear Regression model using the R-squared score on the test set.\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "r2_score( y_test, y_pred)\n",
        "print (\"The r2 score of Linear Regression model is\", r2_score(y_test, y_pred))\n",
        "\n",
        "#6.3 Train a Random Forest Regressor model with 100 estimators on the preprocessed training data.\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rfr = RandomForestRegressor ()\n",
        "rfr.fit(x_train, y_train)\n",
        "y_pred = rfr.predict(x_test)\n",
        "\n",
        "#6.4 Evaluate the performance of the Random Forest Regressor model using the R-squared score on the test set.\n",
        "print (\"The r2 score of Random Forest Regressor is\", r2_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "gIJaIx9XQ7Lt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}