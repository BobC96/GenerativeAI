{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv"
      ],
      "metadata": {
        "id": "TwT2Dkhm8Cit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# 1.1 Import the Titanic dataset from the CSV file.\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/PDAI LIthan/titanic.csv')\n",
        "\n",
        "# 1.2 Perform initial data checks to identify the number of rows and columns in the dataset.\n",
        "# 1.3 Identify and display the count of null values in the Age and cabin columns.\n",
        "df.info()\n",
        "\n",
        "# 2.1 Fill the missing values in the 'Age' column using the mean value.\n",
        "# 2.2 Fill the missing values in the 'Fare' column using the median value.\n",
        "# 2.3 Fill the missing values in the 'Embarked' column with the most common value ('S').\n",
        "df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
        "df['Embarked'].fillna('S', inplace=True)\n",
        "\n",
        "# 3.1 Convert the 'Age' column to an integer type.\n",
        "df['Age'] = df['Age'].astype(int)\n",
        "# 3.2 Create a new binary feature 'Cabin_Exist' indicating the presence or absence of cabin information.\n",
        "df['Cabin_Exist'] = df['Cabin'].isnull()\n",
        "# 3.3 Group the 'Age' and 'Fare' columns into quartiles, creating new features 'Age_Group' and 'Fare_Range'.\n",
        "df['Age_Group'] = pd.qcut(df['Age'], q=4, labels=False)\n",
        "df['Fare_Range'] = pd.qcut(df['Fare'], q=4, labels=False)\n",
        "# 3.4 Create a 'Family' feature by combining 'Parch' and 'SibSp'.\n",
        "df['Family'] = df['SibSp'] + df['Parch']\n",
        "# 3.5 Perform feature selection by dropping irrelevant columns.\n",
        "df.drop(['Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin'], axis=1, inplace=True)\n",
        "\n",
        "# Data encoding\n",
        "label_y = df['Survived']\n",
        "df.drop(\"Survived\", axis=1, inplace=True)\n",
        "x_train, x_test, y_train, y_test = train_test_split(df, label_y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Encode categorical data into binary form using one-hot encoding.\n",
        "x_train_encoded = pd.get_dummies(x_train, drop_first=True)\n",
        "x_test_encoded = pd.get_dummies(x_test, drop_first=True)\n",
        "\n",
        "# Task 5: Data Scaling\n",
        "scaler = MinMaxScaler()\n",
        "train_columns = list(x_train_encoded.columns)\n",
        "\n",
        "# Fit scaler to the training data and transform both training and test data\n",
        "x_train_scaled = scaler.fit_transform(x_train_encoded)\n",
        "x_train_scaled = pd.DataFrame(x_train_scaled, columns=train_columns)\n",
        "x_test_scaled = scaler.transform(x_test_encoded)\n",
        "x_test_scaled = pd.DataFrame(x_test_scaled, columns=train_columns)\n",
        "\n",
        "# Task 6: Model Training and Evaluation\n",
        "lr = LogisticRegression()\n",
        "lr.fit(x_train_scaled, y_train)\n",
        "predictions = lr.predict(x_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print('Accuracy: {:.2f}'.format(accuracy))\n",
        "\n",
        "# Calculate AUC\n",
        "y_scores = lr.predict_proba(x_test_scaled)\n",
        "auc = roc_auc_score(y_test, y_scores[:, 1])\n",
        "print('AUC: {:.2f}'.format(auc))"
      ],
      "metadata": {
        "id": "6rssYKlD8IuP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}